{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Code of your application, which uses environment variables (e.g. from `os.environ` or\n",
    "# `os.getenv`) as if they came from the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761e4289c48241f5902e8bfc5a95b172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import outlines\n",
    "\n",
    "model = outlines.models.transformers(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/outlines/fsm/regex.py:474: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected set' found for argument 'fsm_finals' of function '_walk_fsm'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../.pyenv/versions/llm-playground/lib/python3.10/site-packages/outlines/fsm/regex.py\", line 226:\n",
      "@numba.njit(nogil=True, cache=True)\n",
      "def _walk_fsm(\n",
      "^\n",
      "\n",
      "  state_seq = _walk_fsm(\n",
      "/home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/numba/core/ir_utils.py:2172: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected set' found for argument 'fsm_finals' of function 'state_scan_tokens'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../.pyenv/versions/llm-playground/lib/python3.10/site-packages/outlines/fsm/regex.py\", line 462:\n",
      "@numba.njit(cache=True, nogil=True)\n",
      "def state_scan_tokens(\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are a sentiment-labelling assistant.\n",
    "Is the following review positive or negative?\n",
    "\n",
    "Review: This restaurant is just awesome!\n",
    "\"\"\"\n",
    "answer = outlines.generate.choice(model, [\"Positive\", \"Negative\"])(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick the odd word out: skirt, dress, pen, jacket.\n",
      "skirt is clothing, dress is clothing, pen is an object, jacket is clothing.\n",
      "So the odd one is pen.\n",
      "\n",
      "Pick the odd word out: Spain, France, German, England, Singapore.\n",
      "Spain is a country, France is a country, German is a language, ...\n",
      "So the odd one is German.\n",
      "\n",
      "Pick the odd word out: sea, mountains, plains, sock.\n",
      "sea is a body of water, mountains is a landform, plains is a type of land, sock is a clothing item. \n",
      "So the odd one is sock.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Chain-of-thought prompting for Odd one out classification.\n",
    "\n",
    "Example taken from the LQML library [1]_.\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Beurer-Kellner, L., Fischer, M., & Vechev, M. (2022).\n",
    "       Prompting Is Programming: A Query Language For Large Language Models.\n",
    "       arXiv preprint arXiv:2212.06094.\n",
    "\n",
    "\"\"\"\n",
    "import outlines\n",
    "import outlines.models as models\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "@outlines.prompt\n",
    "def build_ooo_prompt(options):\n",
    "    \"\"\"\n",
    "    Pick the odd word out: skirt, dress, pen, jacket.\n",
    "    skirt is clothing, dress is clothing, pen is an object, jacket is clothing.\n",
    "    So the odd one is pen.\n",
    "\n",
    "    Pick the odd word out: Spain, France, German, England, Singapore.\n",
    "    Spain is a country, France is a country, German is a language, ...\n",
    "    So the odd one is German.\n",
    "\n",
    "    Pick the odd word out: {{ options | join(\", \") }}.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "model = models.openai(\"gpt-3.5-turbo\")\n",
    "\n",
    "options = [\"sea\", \"mountains\", \"plains\", \"sock\"]\n",
    "prompt = build_ooo_prompt(options)\n",
    "reasoning = model(prompt, stop_at=[\"Pick the odd word\", \"So the odd one\"])\n",
    "prompt += reasoning\n",
    "result = model(prompt)\n",
    "prompt += result\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
