{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Code of your application, which uses environment variables (e.g. from `os.environ` or\n",
    "# `os.getenv`) as if they came from the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# This enables response_model keyword\n",
    "# from client.chat.completions.create\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Jason\"\n",
    "assert user.age == 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "aclient = instructor.apatch(AsyncOpenAI())\n",
    "\n",
    "class UserExtract(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "model = await aclient.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserExtract,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract jason is 25 years old\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "assert isinstance(model, UserExtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(UserDetail(name='Jason', age=25), UserExtract(name='Jason', age=25))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bones is a dog\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Pet(BaseModel):\n",
    "    name: str\n",
    "    species: str\n",
    "\n",
    "\n",
    "a = Pet(name='Bones', species='dog')\n",
    "\n",
    "match a:\n",
    "    # match `species` to 'dog', declare and initialize `dog_name`\n",
    "    case Pet(species='dog', name=dog_name): # WTF? I guess it's just unusual destructuring syntax\n",
    "        print(f'{dog_name} is a dog')\n",
    "        #> Bones is a dog\n",
    "    # default case\n",
    "    case _:\n",
    "        print('No dog matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.UserExtract"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': None,\n",
      "                          'function_call': {'arguments': '{\\n'\n",
      "                                                         '  \"name\": \"Jason\",\\n'\n",
      "                                                         '  \"age\": 25\\n'\n",
      "                                                         '}',\n",
      "                                            'name': 'UserExtract'},\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1704604660,\n",
      " 'id': 'chatcmpl-8eFpULHDRddjVmtjq101nPBg99Lp5',\n",
      " 'model': 'gpt-3.5-turbo-0613',\n",
      " 'object': 'chat.completion',\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 16, 'prompt_tokens': 73, 'total_tokens': 89}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "pprint(json.loads(model._raw_response.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import diskcache\n",
    "cache = diskcache.Cache('./my_cache_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 1.57 s, total: 4.38 s\n",
      "Wall time: 6.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(100000):\n",
    "    cache.set(i, list(range(i*i, i*i + 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 ms, sys: 0 ns, total: 2.08 ms\n",
      "Wall time: 2.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in random.sample(range(1000), 100):\n",
    "    cache.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 ms, sys: 0 ns, total: 3.33 ms\n",
      "Wall time: 3.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(500, 600):\n",
    "    cache.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
