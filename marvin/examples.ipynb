{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Code of your application, which uses environment variables (e.g. from `os.environ` or\n",
    "# `os.getenv`) as if they came from the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from marvin import ai_classifier, ai_model, ai_fn, settings\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "settings.openai.api_key=api_key\n",
    "\n",
    "# @ai_classifier(client=client)\n",
    "# #\n",
    "# @ai_model(client=client)\n",
    "# #\n",
    "# @ai_fn(client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/06/24 23:50:18] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> marvin.AIFunction: <span style=\"color: #000080; text-decoration-color: #000080\">Calling: </span><span style=\"color: #800080; text-decoration-color: #800080; background-color: #ffffff; font-weight: bold\">extract</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">((</span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #ffffff\">\"They say they're from the Windy </span>   <a href=\"file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py#88\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000; background-color: #ffffff\">City!\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff\">,</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff\">, </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">{})</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/06/24 23:50:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m marvin.AIFunction: \u001b[34mCalling: \u001b[0m\u001b[1;35;49mextract\u001b[0m\u001b[1;39;49m(\u001b[0m\u001b[1;39;49m(\u001b[0m\u001b[32;49m\"They say they're from the Windy \u001b[0m   \u001b]8;id=392107;file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=445416;file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py#88\u001b\\\u001b[2m88\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32;49mCity!\"\u001b[0m\u001b[39;49m,\u001b[0m\u001b[1;39;49m)\u001b[0m\u001b[39;49m, \u001b[0m\u001b[1;39;49m{\u001b[0m\u001b[1;39;49m}\u001b[0m\u001b[1;39;49m)\u001b[0m                                                            \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Location(city='Chicago', state='Illinois', latitude=41.8781, longitude=-87.6298)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from marvin.components import ai_model\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "\n",
    "ai_model(Location)(\"They say they're from the Windy City!\")\n",
    "# Location(city='Chicago', state='Illinois', latitude=41.8781, longitude=-87.6298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pharmacy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from marvin import ai_classifier\n",
    "from typing import Literal\n",
    "\n",
    "@ai_classifier\n",
    "def customer_intent(text: str) -> Literal['Store Hours', 'Pharmacy', 'Returns']:\n",
    "    \"\"\"Classifies incoming customer intent\"\"\"\n",
    "\n",
    "customer_intent(\"I need to pick up my prescription\") # \"Pharmacy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/06/24 23:50:36] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> marvin.AIFunction: <span style=\"color: #000080; text-decoration-color: #000080\">Calling: </span><span style=\"color: #800080; text-decoration-color: #800080; background-color: #ffffff; font-weight: bold\">list_fruits</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #ffffff; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff\">,</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff\">, </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffffff; font-weight: bold\">{})</span>                        <a href=\"file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py#88\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/06/24 23:50:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m marvin.AIFunction: \u001b[34mCalling: \u001b[0m\u001b[1;35;49mlist_fruits\u001b[0m\u001b[1;39;49m(\u001b[0m\u001b[1;39;49m(\u001b[0m\u001b[1;36;49m3\u001b[0m\u001b[39;49m,\u001b[0m\u001b[1;39;49m)\u001b[0m\u001b[39;49m, \u001b[0m\u001b[1;39;49m{\u001b[0m\u001b[1;39;49m}\u001b[0m\u001b[1;39;49m)\u001b[0m                        \u001b]8;id=638106;file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=634055;file:///home/jacobjensen/.pyenv/versions/llm-playground/lib/python3.10/site-packages/marvin/utilities/logging.py#88\u001b\\\u001b[2m88\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['apple', 'cherry', 'strawberry']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from marvin import ai_fn\n",
    "\n",
    "@ai_fn\n",
    "def list_fruits(n: int, color: str = 'red') -> list[str]:\n",
    "    \"\"\"Generates a list of {{ n }} {{ color }} fruits\"\"\"\n",
    "\n",
    "list_fruits(3) # \"['Apple', 'Cherry', 'Strawberry']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': <function __main__.list_fruits(n: int, color: str = 'red') -> list[str]>,\n",
       " 'environment': None,\n",
       " 'prompt': '        Your job is to generate likely outputs for a Python function with the\\n        following signature and docstring:\\n\\n        {{_source_code}}\\n\\n        The user will provide function inputs (if any) and you must respond with\\n        the most likely result.\\n\\n        \\n\\nHUMAN: The function was called with the following inputs:\\n        {%for (arg, value) in _arguments.items()%}\\n        - {{ arg }}: {{ value }}\\n        {% endfor %}\\n\\n        What is its output?\\n    ',\n",
       " 'name': 'FormatResponse',\n",
       " 'description': 'Formats the response.',\n",
       " 'field_name': 'data',\n",
       " 'field_description': 'The data to format.',\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'temperature': 0.1,\n",
       " 'client': <openai.OpenAI at 0x7f2d788a5a50>,\n",
       " 'aclient': <openai.AsyncOpenAI at 0x7f2d789aa050>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
